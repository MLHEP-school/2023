{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "SflzDJRWA76t"
      },
      "source": [
        "# PyTorch intro\n",
        "\n",
        "Seminar outline:\n",
        "\n",
        "- Data load\n",
        "- Automatic differentiation\n",
        "- From nn.Sequential to nn.Module\n",
        "- TensorBoard\n",
        "\n",
        "![tensorboard](https://www.tensorflow.org/static/tensorboard/images/tensorboard.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrbLmPhoA77R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imo8-TciBDih"
      },
      "outputs": [],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pIR7FTq6A77e"
      },
      "source": [
        "\n",
        "## Data load\n",
        "\n",
        "All dataset classes are subclasses of [`torch.util.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) have `__getitem__` and `__len__` methods implemented. Thus, it can be passed to a [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), which can load multiple samples parallelly.\n",
        "Popular Dataset subclasses:\n",
        "\n",
        "- [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist)\n",
        "- [Fashion-MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#fashion-mnist)\n",
        "- [CIFAR](https://pytorch.org/docs/stable/torchvision/datasets.html#cifar)\n",
        "- [CelebA](https://pytorch.org/docs/stable/torchvision/datasets.html#celeba)\n",
        "\n",
        "`MNIST` constructor signature: `torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)`, where `transform` - function/transform that takes in an PIL (Height x Width x Channels) image and returns a transformed version. \n",
        "\n",
        "Several transformations can be combined together. Popular transformations:\n",
        "- `torchvision.transforms.Normalize(mean, std, inplace=False)`\n",
        "- `torchvision.transforms.ToTensor()` - Converts a PIL Image or `numpy.ndarray` (H x W x C) in the range `[0, 255]` to a `torch.FloatTensor` of shape (C x H x W) in the range `[0.0, 1.0]` \n",
        "\n",
        "\n",
        "DataLoader constructor signature\n",
        "`torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None)`, where\n",
        "- dataset is DataSet instance\n",
        "- batch_size - number of items sampled at every iteration\n",
        "- num_workers - number of simultaneous reading processes (**NB** on Windows you might want to set it to `0`)\n",
        "\n",
        "DataLoaders provide convenient interface for training loops: \n",
        "\n",
        "```python\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            ...\n",
        "            \n",
        "```\n",
        "or \n",
        "```python\n",
        "    batch_X, batch_y = iter(trainloader).next()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pOnXdn0A77g"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "ds_train = datasets.MNIST(\".\", train=True, download=True, transform=transform)\n",
        "ds_test = datasets.MNIST(\".\", train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(ds_train, batch_size=512,\n",
        "                                        shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(ds_test, batch_size=10000,\n",
        "                                        shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmnC8Dm6A77h"
      },
      "outputs": [],
      "source": [
        "print(\"Train:\", ds_train, \"\\nTest:\", ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm5Iv7AQA77i"
      },
      "outputs": [],
      "source": [
        "X_batch, y_batch = next(iter(trainloader))\n",
        "print(\"batch size:\", len(X_batch), \"batch dimensions:\", X_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGj7IIYHA77i"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 4), dpi=100)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.imshow(\n",
        "    torch.transpose(\n",
        "        torch.cat(\n",
        "            [X_batch[y_batch == c][:10] for c in range(10)], axis=0\n",
        "        ).reshape(10, 10, 28, 28),\n",
        "        1, 2\n",
        "    ).reshape(280, 280)\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "H0247JpUA77i"
      },
      "source": [
        "## Automatic differentiation\n",
        "Automatic differentiaion is the main mechanism for the backpropagation in PyTorch. PyTorch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
        "\n",
        "You can turn off gradients for a block of code with the `torch.no_grad()` context:\n",
        "\n",
        "```\n",
        "x = torch.zeros(1, requires_grad=True)\n",
        ">>> with torch.no_grad():\n",
        "...     y = x * 2\n",
        ">>> y.requires_grad\n",
        "False\n",
        "```\n",
        "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
        "\n",
        "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF1CDDQlA77j"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd4DWYySA77j"
      },
      "outputs": [],
      "source": [
        "y = x**2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "VJdQiltLA77j"
      },
      "source": [
        "Below we can see the operation that created `y`, a power operation `PowBackward0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjNcTHe5A77j"
      },
      "outputs": [],
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "dvkcNKdAA77j"
      },
      "source": [
        "The autograd module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc2alAh7A77k"
      },
      "outputs": [],
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kDLn39y_A77k"
      },
      "source": [
        "You can check the gradients for `x` and `y` but they are empty currently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgkGLpQOA77k"
      },
      "outputs": [],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ibyIiCwqA77k"
      },
      "source": [
        "To calculate the gradients, you need to run the `.backward` method on a variable `z`, for example. This will calculate the gradient for `z` with respect to `x`\n",
        "\n",
        "$$\\frac{\\partial z}{\\partial x}=\\frac{\\partial}{\\partial x}\\left[\\frac{1}{n} \\sum_{i}^{n} x_{i}^{2}\\right]=\\frac{x}{2}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huewarNeA77k"
      },
      "outputs": [],
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xcFFWOTpA77l"
      },
      "source": [
        "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the weights with respect to the cost. With PyTorch, we run data forward through the network to calculate the loss, then, go backwards to calculate the gradients with respect to the loss. Once we have the gradients we can make a gradient descent step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7rNXnFn8A77l"
      },
      "source": [
        "## Loss and Autograd together\n",
        "When we create a network with PyTorch, all of the parameters are initialized with `requires_grad = True`. This means that when we calculate the loss and call `loss.backward()`, the gradients for the parameters are calculated. These gradients are used to update the weights with gradient descent. Below you can see an example of calculating the gradients using a backwards pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6VizNLmA77l"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():         \n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# create a network that stacks layers on top of each other\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 100), # add first \"dense\" layer with 784 input\n",
        "                         # units and 100 output units (hidden layer\n",
        "                         # with 100 neurons).\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 10), # \"dense\" layer with 10 output\n",
        "                        # units (for 10 classes).\n",
        ").to(device)\n",
        "\n",
        "print(\"Weight shapes:\")\n",
        "for w in model.parameters():\n",
        "    print(\"  \", w.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "6WMOqFkPA77m"
      },
      "source": [
        "If we give our batch to the model, we get an exception of dimension mismatch, since batch dimensions are 512 x 28 x 28 x 1, while model expects 512 x 784, so we need to flatten the trailing dimensions. You can use method `torch.flatten(input, start_dim=0, end_dim=-1) → Tensor`\n",
        "\n",
        "    >>> t = torch.tensor([[[1, 2],\n",
        "                       [3, 4]],\n",
        "                      [[5, 6],\n",
        "                       [7, 8]]])\n",
        "    >>> torch.flatten(t)\n",
        "    tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
        "    >>> torch.flatten(t, start_dim=1)\n",
        "    tensor([[1, 2, 3, 4],\n",
        "            [5, 6, 7, 8]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEa2Rw5zA77m",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-1c1cd227b609261d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def flatten_trailing(batch):\n",
        "    ### YOUR CODE HERE\n",
        "    return flat_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzkRpoKZA77m",
        "nbgrader": {
          "grade": true,
          "grade_id": "flatten",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "assert flatten_trailing(X_batch).shape == (512, 784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnDN6nCKA77n"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "predictions = model(flatten_trailing(X_batch.to(device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqfWuHBLA77n"
      },
      "outputs": [],
      "source": [
        "loss = loss_fn(predictions, y_batch.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHim5zHqA77n"
      },
      "outputs": [],
      "source": [
        "print('Before backward pass: \\n', model[2].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[2].weight.grad[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "AEUXcqUTA77n"
      },
      "source": [
        "If we try to call backward once again, the graph buffers are deallocated and we are going to get \n",
        "> RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6-blyyOA77n"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    loss.backward()\n",
        "except Exception as e:\n",
        "    print(\"Got Exception\", type(e), e)\n",
        "else:\n",
        "    print(\"No exception\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "wPtF1FMzA77o"
      },
      "source": [
        "## From nn.Sequential to nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zxlAdcYA77o"
      },
      "outputs": [],
      "source": [
        "def train(model, num_epochs=1, batch_size=512, loss_fn=loss_fn, device='cpu'):\n",
        "    # some quantities to plot\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_accuracy = []\n",
        "    model_dev = model.to(device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for i_epoch in range(num_epochs):\n",
        "        t = tqdm.tqdm(iter(trainloader), leave=False, total=len(trainloader))\n",
        "        for idx, data in enumerate(t):\n",
        "            # get the next chunk (batch) of data:\n",
        "            batch_X, batch_y = map(lambda x: x.to(device), data)\n",
        "\n",
        "            # all the black magic:\n",
        "            loss = loss_fn(model(flatten_trailing(batch_X)), batch_y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # remember the loss value at this step\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        # evaluate test loss and metrics\n",
        "        test_X, test_y = map(lambda x: x.to(device), next(iter(testloader)))\n",
        "\n",
        "        test_prediction = model(flatten_trailing(test_X.to(device)))\n",
        "        test_losses.append(\n",
        "            loss_fn(test_prediction, test_y).item()\n",
        "        )\n",
        "        test_accuracy.append(\n",
        "            (test_prediction.argmax(axis=1) == test_y).to(float).mean()\n",
        "        )\n",
        "\n",
        "        # all the rest is simply plotting\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        plt.figure(figsize=(8, 3), dpi=100)\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(train_losses, label='train')\n",
        "        plt.plot(\n",
        "            np.linspace(0, len(train_losses), len(test_losses) + 1)[1:],\n",
        "            test_losses, label='test'\n",
        "        )\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.xlabel(\"# steps\")\n",
        "        plt.legend();\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(test_accuracy, \"o-\")\n",
        "        plt.ylabel(\"Test accuracy\")\n",
        "        plt.xlabel(\"# epochs\");\n",
        "        plt.show()\n",
        "    return train_losses, test_losses, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "910pHr6_A77o"
      },
      "outputs": [],
      "source": [
        "train(model, num_epochs=2, device=device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFn5wDRNA77o"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, n=100):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, n)\n",
        "        self.fc2 = nn.Linear(n, 10)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        Xf = X.flatten(1) # we add `flatten` here\n",
        "        X1 = F.relu(self.fc1(Xf))\n",
        "        return self.fc2(X1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta7vukobA77p"
      },
      "outputs": [],
      "source": [
        "print(device)\n",
        "model2 = Net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXuzpz0DA77p"
      },
      "outputs": [],
      "source": [
        "train(model2, device=device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rlYJJWACA77p"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yStYkGlvA77p"
      },
      "source": [
        "Now we’ll set up TensorBoard, importing `tensorboard` from `torch.utils` and creating a `SummaryWriter` - the key object for writing information to TensorBoard. Useful methods of [`SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter#torch.utils.tensorboard.writer.SummaryWriter):\n",
        "- add_scalar - for storing points that can be visualized as plots\n",
        "- add_histogram - for storing histograms\n",
        "- add_image - for storing images \n",
        "- add_figure - for storing matplotlib figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7zj9R70A77q"
      },
      "outputs": [],
      "source": [
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/MNIST_Y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4yAtb5qAA77q"
      },
      "source": [
        "Note that this line creates a `runs/MNIST_X` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hftNdA0A77q"
      },
      "outputs": [],
      "source": [
        "train_X, train_y = map(lambda x: x.to(device), next(iter(trainloader)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoDOwqkmA77q"
      },
      "outputs": [],
      "source": [
        "img = torch.transpose(\n",
        "        torch.cat(\n",
        "            [train_X[train_y == c][:10] for c in range(10)], axis=0\n",
        "        ).reshape(10, 10, 28, 28),\n",
        "        1, 2\n",
        "    ).reshape(280, 280).cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EChqlk88A77q"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ArSQo-tA77r"
      },
      "outputs": [],
      "source": [
        "# the last argument of add_image is image in CxHxW format\n",
        "writer.add_image('MNIST', img.view(1, 280, 280))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3knOnaFC3t-"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVHTCSxWDL_W"
      },
      "outputs": [],
      "source": [
        "!ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qVs2vm-DUk1"
      },
      "outputs": [],
      "source": [
        "!kill 3120"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7WVIFmfyA77r"
      },
      "source": [
        "`.add_graph` stores graph of the model in the interactive form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA1a9qJkA77r"
      },
      "outputs": [],
      "source": [
        "writer.add_graph(model2, train_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSLZd0nJA77r"
      },
      "outputs": [],
      "source": [
        "# helper functions\n",
        "def matplotlib_imshow(img, one_channel=True):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.cpu().numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "def images_to_probs(net, images):\n",
        "    '''\n",
        "    Generates predictions and corresponding probabilities from a trained\n",
        "    network and a list of images\n",
        "    '''\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
        "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "\n",
        "def plot_classes_preds(net, images, labels, classes):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "    preds, probs = images_to_probs(net, images)\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(12, 3))\n",
        "    for idx in np.arange(4):\n",
        "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
        "        matplotlib_imshow(images[idx], one_channel=True)\n",
        "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "            classes[preds[idx]],\n",
        "            probs[idx] * 100.0,\n",
        "            classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cm2fQbEA77r"
      },
      "outputs": [],
      "source": [
        "def train_tb(model, num_epoch=1, batch_size=512, device='cpu', tag='training loss'):\n",
        "    running_loss = 0.0\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "        t = tqdm.tqdm(iter(trainloader), leave=False, total=len(trainloader))\n",
        "        for idx, data in enumerate(t):\n",
        "            # get the next chunk (batch) of data:\n",
        "            batch_X, batch_y = map(lambda x: x.to(device), data)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(batch_X)\n",
        "            loss = loss_fn(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            writer.add_scalar(tag,\n",
        "                            loss.item(),\n",
        "                            epoch * len(batch_y) + idx)\n",
        "            if idx % 20 == 0:\n",
        "                writer.add_figure(f'{tag}/predictions_vs_actuals',\n",
        "                            plot_classes_preds(model,\n",
        "                                               batch_X[:4],\n",
        "                                               batch_y[:4],\n",
        "                                               trainloader.dataset.classes),\n",
        "                            global_step=epoch * len(trainloader) + idx)\n",
        "\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68deFYyuA77s"
      },
      "outputs": [],
      "source": [
        "model3 = Net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrJD8FlpA77s"
      },
      "outputs": [],
      "source": [
        "train_tb(model3, device=device, tag='MyTraining-2')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "iQB6VxjQA77s"
      },
      "source": [
        "Every 20 iterations of the training loop we have saved images with predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "frKUp6a6A77s"
      },
      "source": [
        "In case your notebook is running **locally** you can upload your tensorboard state to public service [https://tensorboard.dev/](https://tensorboard.dev/) by running command \n",
        "\n",
        "```bash\n",
        "tensorboard dev upload --logdir runs \\\n",
        "  --name \"My latest experiment\" \\ # optional\n",
        "  --description \"Simple comparison of several hyperparameters\" # optional\n",
        "```\n",
        "\n",
        "**Note:** Uploaded TensorBoards are public and visible to everyone. Do not upload sensitive data.\n",
        "\n",
        "For help, run `$ tensorboard dev upload --help.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhA8WaUiEGdD"
      },
      "outputs": [],
      "source": [
        "!tensorboard dev upload --logdir runs --name \"My latest experiment\" --description \"Simple comparison of several hyperparameters\" --one_shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rjs6xrIERqc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5GC1FVaQA77s"
      },
      "source": [
        "### More information on tensorboard:\n",
        "\n",
        "- https://pytorch.org/docs/stable/tensorboard.html\n",
        "- https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\n",
        "- https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
        "- https://tensorboard.dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg8d_C2KA77s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
