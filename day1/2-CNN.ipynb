{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "wBE9GIubrYDC"
      },
      "source": [
        "# Deep learning for computer vision\n",
        "\n",
        "![image](https://discuss.pytorch.org/uploads/default/original/2X/b/be78292481e56065190ad57e784f42062842c7fa.gif)\n",
        "\n",
        "This notebook will teach you to build and train convolutional networks for image recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umUCOiHFrYDk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import tqdm\n",
        "import torch\n",
        "import functools\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "S-h53q28Jd8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH2rx4fVHKE7"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "ds1 = datasets.FashionMNIST(\"data\", train=True, download=True, transform=transform)\n",
        "ds_test = datasets.FashionMNIST(\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "ds_train, ds_val = torch.utils.data.random_split(ds1, [50000, 10000])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(ds_train, batch_size=32,\n",
        "                                        shuffle=True, num_workers=2)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(ds_val, batch_size=10000,\n",
        "                                        shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(ds_test, batch_size=10000,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print(\"Training+Val:\", ds1,\n",
        "     \"\\nTest:\", ds_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kSTZbU4zHKE7"
      },
      "source": [
        "**Fashion-MNIST** is a 10-class dataset of 28x28 grayscale images of various kind of fashion items (Zalando's article items). Named after the famous MNIST dataset with hand-written digits. Lets display a few of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmYQZIOXHKE7"
      },
      "outputs": [],
      "source": [
        "# helper function to show an image\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.cpu().numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYsiAJkDHKE8"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "BQgZ87NjHKE8"
      },
      "source": [
        "Checking for available GPU device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmwOkQpsHKE8"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    print('Selected %s' % (device))\n",
        "else:\n",
        "    device = 'cpu'\n",
        "    print('WARNING: using cpu!')\n",
        "\n",
        "### please, don't remove the following line\n",
        "x = torch.tensor([1], dtype=torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "MM8T9MISrYEM"
      },
      "source": [
        "# Building a baseline network\n",
        "\n",
        "Simple neural networks with layers applied on top of one another can be implemented either as `torch.nn.Sequential` or as a subclass of `torch.nn.Module`. \n",
        "\n",
        "__Convolutional layers__ in torch are just like all other layers, but with a specific set of parameters:\n",
        "\n",
        "__`nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)`__\n",
        "\n",
        "__`nn.MaxPool2d(kernel_size)`__\n",
        "\n",
        "Let's start with a simple baseline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f43dEPxzrYEb"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 4, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(676, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = x.flatten(1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "    \n",
        "model = Net().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Xk4XvZcBrYEk"
      },
      "source": [
        "As in our basic tutorial, we train our model with negative log-likelihood aka crossentropy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vonT0yO7HKE9"
      },
      "outputs": [],
      "source": [
        "def model_count_params(model):\n",
        "    return np.sum([s.numel() for s in model.parameters()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0RGtIAirYE0"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter('runs/F-MNIST_CNN-3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5udxRczHKE-"
      },
      "outputs": [],
      "source": [
        "\n",
        "writer.add_scalar(\"model/size\", model_count_params(model))\n",
        "print(\"Model size:\", model_count_params(model))\n",
        "writer.add_graph(model, images.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4dc4a1834191d4dc",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Sga-TVKLHKE-"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculates the accuracy of the prediction\n",
        "    y_true is N-vector of integers for N-item batch\n",
        "    y_pred is a tensor N x 10 of 10-dimensional network component output\n",
        "    \n",
        "    You have to find the number of the highest component output\n",
        "    and compare it with y_true and compute average number of exact matches.\n",
        "    \n",
        "    Returs: average number of exact matches \n",
        "    \"\"\"\n",
        "    # to find maximum item in the tensor along i dimension use .max(dim=i)\n",
        "    # to count number of matching items use '==' operator\n",
        "    # \n",
        "    ### BEGIN SOLUTION\n",
        "    n_pred = y_pred.max(dim=1)[1]\n",
        "    accuracy = torch.sum(y_true == n_pred).item()/len(y_true)\n",
        "    ### END SOLUTION\n",
        "    \n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "accuracy_proc",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tlsUPiqlHKE-"
      },
      "outputs": [],
      "source": [
        "assert accuracy(torch.ones(1000), torch.rand(1000,2)) > 0.4 \n",
        "assert accuracy(torch.ones(1000), torch.rand(1000,2)) < 0.6\n",
        "assert accuracy(torch.ones(10), torch.cat([torch.ones(10,1), torch.zeros(10,1)], dim=1)) == 0\n",
        "assert accuracy(torch.ones(10), torch.cat([torch.zeros(10,1), torch.ones(10,1)], dim=1)) == 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-_8H7-RHKE-"
      },
      "outputs": [],
      "source": [
        "# helper functions\n",
        "def plot_classes_preds(net, images, labels, classes):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "    preds, probs = images_to_probs(net, images)\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    for idx in np.arange(16):\n",
        "        ax = fig.add_subplot(4, 4, idx+1, xticks=[], yticks=[])\n",
        "        matplotlib_imshow(images[idx], one_channel=True)\n",
        "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "            classes[preds[idx]],\n",
        "            probs[idx] * 100.0,\n",
        "            classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "#         plt.cla()\n",
        "    return fig\n",
        "\n",
        "def images_to_probs(net, images):\n",
        "    '''\n",
        "    Generates predictions and corresponding probabilities from a trained\n",
        "    network and a list of images\n",
        "    '''\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
        "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGvd4VpLHKE_"
      },
      "outputs": [],
      "source": [
        "def train(model, writer, num_epochs=1, device='cpu'):\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_loss = []\n",
        "    test_accuracy = []\n",
        "    running_loss = 0\n",
        "    epoch_iter = tqdm.trange(num_epochs)\n",
        "    for epoch in epoch_iter:\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = map(lambda x: x.to(device), data)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                writer.add_scalar('Loss/training',\n",
        "                                running_loss / 1000,\n",
        "                                epoch * len(trainloader) + i)\n",
        "                running_loss = 0.0\n",
        "                fig = plot_classes_preds(model, inputs, labels, ds_test.classes)\n",
        "                writer.add_figure('predictions vs. actuals', fig, global_step=epoch * len(trainloader) + i)\n",
        "                plt.close(fig)\n",
        "                del fig\n",
        "\n",
        "        for X_batch, y_batch in DataLoader(ds_val, batch_size=len(ds_val)):\n",
        "            test_accuracy.append(\n",
        "                accuracy(\n",
        "                    y_batch.to(device),\n",
        "                    model(X_batch.to(device))))\n",
        "\n",
        "        writer.add_scalar('Loss/val',\n",
        "                            test_accuracy[-1],\n",
        "                            epoch)\n",
        "        epoch_iter.set_description(f\"Accuracy: {test_accuracy[-1]:.3f}\")\n",
        "    plt.close('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "BKE8apN-HKE_"
      },
      "outputs": [],
      "source": [
        "# if you get RuntimeWarning: More than 20 figures have been opened., don't worry, all figures are closed at the end of train proc\n",
        "train(model, writer, num_epochs=5, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "VLRF560FHKE_"
      },
      "source": [
        "Now you can open Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "zQ3m9MHwKovT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OJy3BBGKrYFE"
      },
      "source": [
        "### Final test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iKXTHsCrYFG",
        "nbgrader": {
          "grade": false,
          "grade_id": "2ea31c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def test_model(model, writer):\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    test_accuracy = 0\n",
        "    cpu_model = model.to('cpu')\n",
        "    cpu_model.train(False)\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in DataLoader(ds_test, batch_size=len(ds_test)):\n",
        "            output = cpu_model(X_batch)\n",
        "            test_accuracy = 100 * accuracy(y_batch, output)\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct_tensor = pred.eq(y_batch.data.view_as(pred))\n",
        "            correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "            for i in range(len(y_batch)):\n",
        "                label = y_batch.data[i]\n",
        "                class_correct[label] += correct[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(f\"  test accuracy:\\t\\t{test_accuracy:.2f}\")\n",
        "\n",
        "    if test_accuracy > 98:\n",
        "        print(\"U'r freakin' amazin'!\")\n",
        "    elif test_accuracy > 95:\n",
        "        print(\"Achievement unlocked: 110lvl Warlock!\")\n",
        "    elif test_accuracy > 90:\n",
        "        print(\"Achievement unlocked: 80lvl Warlock!\")\n",
        "    elif test_accuracy > 85:\n",
        "        print(\"Achievement unlocked: 70lvl Warlock!\")\n",
        "    else:\n",
        "        print(\"We need more magic! Follow instructons below\")\n",
        "    \n",
        "    print(\"-\" * 40)\n",
        "    for i in range(10):\n",
        "        if class_total[i] > 0:\n",
        "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "                ds_test.classes[i], 100 * class_correct[i] / class_total[i],\n",
        "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "        else:\n",
        "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "        \n",
        "    writer.add_scalar(\"Loss/test\", test_accuracy)\n",
        "    return test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "model_accuracy",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "TNNXbCLZHKFA"
      },
      "outputs": [],
      "source": [
        "\n",
        "%time acc = test_model(model, writer)\n",
        "assert acc > 80\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "SmFLssyIrYFS"
      },
      "source": [
        "## Task: improve convolution net\n",
        "\n",
        "Let's create a mini-convolutional network with an architecture like this:\n",
        "\n",
        "* 3x3 convolution with 8 filters, padding=1 and _ReLU_ activation\n",
        "* 2x2 pooling\n",
        "* 3x3 convolution with 16 filters, padding=1 and _ReLU_ activation\n",
        "* 4x4 pooling\n",
        "* flatten\n",
        "* Linear layer with ~180 input and ~100 output sizes and _ReLU_ activation\n",
        "* output linear layer\n",
        "\n",
        "\n",
        "To find the size of the 1st linear layer you can run the cell below and \n",
        "if it throws error like this: \n",
        "\n",
        "    RuntimeError: size mismatch, m1: [32 x 784], m2: [144 x 100], \n",
        "  \n",
        "you should change the size of the Linear layer to 784.\n",
        "\n",
        "Once you're done, train it with __Adam__ optimizer with default params (feel free to modify the `train` procedure above).\n",
        "\n",
        "\n",
        "__TIP_OF_THE_DAY__: the number of channels must be similar to the number of classes (same order of magnitude)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRTq8rxPrYFU",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c99d6ea1d3938f86",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        # put all the layer initialization here\n",
        "        ### BEGIN SOLUTION\n",
        "        self.conv1 = nn.Conv2d(1,  8,  3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(8,  16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(784, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        ### END SOLUTION\n",
        "\n",
        "    def forward(self, x):\n",
        "        # pass x through all the layers\n",
        "        ### BEGIN SOLUTION\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.flatten(1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        ### END SOLUTION\n",
        "        return x\n",
        "    \n",
        "model2 = Net2().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "31NP8etbrYFr"
      },
      "source": [
        "## Train it ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1SDz69cHKFB"
      },
      "outputs": [],
      "source": [
        "writer2 = SummaryWriter('runs/F-MNIST_CNN-redux-1')\n",
        "writer2.add_scalar(\"model/size\", model_count_params(model2))\n",
        "writer2.add_graph(model2, images.to(device))\n",
        "writer2.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-OZN8EaHKFB"
      },
      "outputs": [],
      "source": [
        "model_count_params(model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "wApr-JMoHKFB"
      },
      "outputs": [],
      "source": [
        "train(model2, writer2, num_epochs=20, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4tm9gX5YHKFB"
      },
      "source": [
        "## Test it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0_7ihSnrYF2",
        "nbgrader": {
          "grade": true,
          "grade_id": "model2_accuracy",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "%time acc = test_model(model2, writer2);\n",
        "writer2.close()\n",
        "assert acc > 90"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "K5bf3W6NHKFB"
      },
      "source": [
        "Hopefully you've managed to succeed. If not, you may always come back to this task after looking at at more advanced topics, e.g. regularization and batch normalization.\n",
        "\n",
        "**Question**: What are your model's weaknesses and how might they be improved?\n",
        "\n",
        "**Answer**: This model seems to do best on boots rather than coats. For example, it does best on the Sandal class and worst on the Shirt class. Maybe it's because Shirts vary in size and so it would improve this model if you could increase the number of shirt images in the first place or perhaps if one added another convolutional layer to detect finer patterns in these images. One could also experiment with a smaller learning rate so that the model takes small steps in the right direction as it is training.\n",
        "\n",
        "Images with correct and predicted labels like the one below are stored in Tensorboard images during the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmMhwSmwHKFB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Create Assignment",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}