{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gHvlahm8sdHn"
      },
      "source": [
        "# Skorch introduction\n",
        "\n",
        "(borrowed from skorch documentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8C_Zi4PosdHp"
      },
      "source": [
        "*`skorch`* is designed to maximize interoperability between `sklearn` and `pytorch`. The aim is to keep 99% of the flexibility of `pytorch` while being able to leverage most features of `sklearn`. Below, we show the basic usage of `skorch` and how it can be combined with `sklearn`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iYcmHUz2sdHw"
      },
      "outputs": [],
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LrER0JNHsdH7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fp45SEoesdIA"
      },
      "source": [
        "## Training a classifier and making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IdH4bpDAsdID"
      },
      "source": [
        "### A toy binary classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ZIe445asdIF"
      },
      "source": [
        "We load a toy classification task from `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_RyajDFzsdIH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.manifold import locally_linear_embedding\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jlvFVXbEsdIN"
      },
      "outputs": [],
      "source": [
        "X, y = make_classification(2000, 20, n_informative=10, n_classes=2, random_state=0)\n",
        "X = X.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3UN4yjlysdIa",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "X.shape, y.shape, y.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_reduced, err = locally_linear_embedding(X, n_neighbors=5, n_components=2)\n",
        "# PCA would be a better choice here, but LLE is more fun\n",
        "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap='bwr', alpha=0.5);\n",
        "X_reduced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CC2yNBMTsdIm"
      },
      "source": [
        "### Definition of the `pytorch` classification `module`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7oe_jOBXsdIn"
      },
      "source": [
        "We define a vanilla neural network with two hidden layers. The output layer should have 2 output units since there are two classes. In addition, it should have a softmax nonlinearity, because later, when calling `predict_proba`, the output from the `forward` call will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "u0V9nuedsdIo"
      },
      "outputs": [],
      "source": [
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=10,\n",
        "            nonlin=F.relu,\n",
        "            dropout=0.5,\n",
        "    ):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.dense0 = nn.Linear(20, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.dense1 = nn.Linear(num_units, 10)\n",
        "        self.output = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = self.nonlin(self.dense0(X))\n",
        "        X = self.dropout(X)\n",
        "        X = F.relu(self.dense1(X))\n",
        "        X = F.softmax(self.output(X), dim=-1)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pj-n5AgUsdIs"
      },
      "source": [
        "### Defining and training the neural net classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hJ7PzCqosdIv"
      },
      "source": [
        "We use `NeuralNetClassifier` because we're dealing with a classifcation task. The first argument should be the `pytorch module`. As additional arguments, we pass the number of epochs and the learning rate (`lr`), but those are optional.\n",
        "\n",
        "*Note*: To use the CUDA backend, pass `device='cuda'` as an additional argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "s9MsKiTPsdIw"
      },
      "outputs": [],
      "source": [
        "from skorch import NeuralNetClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MPqytGnpsdI-"
      },
      "outputs": [],
      "source": [
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    lr=0.1,\n",
        "    # device='cuda',  # comment this to train with CPU\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UrJKaypCsdJK"
      },
      "source": [
        "As in `sklearn`, we call `fit` passing the input data `X` and the targets `y`. By default, `NeuralNetClassifier` makes a `StratifiedKFold` split on the data (80/20) to track the validation loss. This is shown, as well as the train loss and the accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LVYsuRmlsdJR",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "net.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A4Iboct1sdJa"
      },
      "source": [
        "Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWVppbCEsdJb"
      },
      "source": [
        "### Making predictions, classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "B2mAMsh6sdJc"
      },
      "outputs": [],
      "source": [
        "y_pred = net.predict(X[:5])\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NtRHJIiQsdJf"
      },
      "outputs": [],
      "source": [
        "y_proba = net.predict_proba(X[:5])\n",
        "y_proba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zDxsb514sdJj"
      },
      "source": [
        "## Usage with sklearn `GridSearchCV`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Ygtq1a5sdJj"
      },
      "source": [
        "### Special prefixes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MlLAYtb4sdJk"
      },
      "source": [
        "The `NeuralNet` class allows to directly access parameters of the `pytorch module` by using the `module__` prefix. So e.g. if you defined the `module` to have a `num_units` parameter, you can set it via the `module__num_units` argument. This is exactly the same logic that allows to access estimator parameters in `sklearn Pipeline`s and `FeatureUnion`s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ezV8EqGsdJm"
      },
      "source": [
        "This feature is useful in several ways. For one, it allows to set those parameters in the model definition. Furthermore, it allows you to set parameters in an `sklearn GridSearchCV` as shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TE1UKqnRsdJn"
      },
      "source": [
        "In addition to the parameters prefixed by `module__`, you may access a couple of other attributes, such as those of the optimizer by using the `optimizer__` prefix (again, see below). All those special prefixes are stored in the `prefixes_` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rAZ6pbwJsdJo"
      },
      "outputs": [],
      "source": [
        "print(', '.join(net.prefixes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Iv2vi2wjsdJy"
      },
      "source": [
        "### Performing a grid search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S68rq4W5sdJy"
      },
      "source": [
        "Below we show how to perform a grid search over the learning rate (`lr`), the module's number of hidden units (`module__num_units`), the module's dropout rate (`module__dropout`), and whether the SGD optimizer should use Nesterov momentum or not (`optimizer__nesterov`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OaLce-aasdJz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U3-mOrJgsdJ1"
      },
      "outputs": [],
      "source": [
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    lr=0.1,\n",
        "    verbose=0,\n",
        "    optimizer__momentum=0.9,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0ZMTv4YOsdJ5"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'lr': [0.05, 0.1],\n",
        "    'module__num_units': <YOUR CODE>, # range from 10 to 50\n",
        "    'module__dropout': <YOUR CODE>, # range from 0.1 to 0.3\n",
        "    'optimizer__nesterov': [False, True],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = {\n",
        "    'lr': [0.05, 0.1],\n",
        "    'module__num_units': np.arange(10, 50, 10), # range from 10 to 50\n",
        "    'module__dropout': np.linspace(0.1, 0.3, 3), # range from 0.1 to 0.3\n",
        "    'optimizer__nesterov': [False, True],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VWsXCeSLsdJ-"
      },
      "outputs": [],
      "source": [
        "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', \n",
        "                  verbose=1, n_jobs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xJVYZwzZsdKF"
      },
      "outputs": [],
      "source": [
        "gs.fit(X, y);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bnUo1MB-ujou"
      },
      "outputs": [],
      "source": [
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dEzEOrqhuklH"
      },
      "outputs": [],
      "source": [
        "report(gs.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "X9TnlAsdunVL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "2-skorch.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
